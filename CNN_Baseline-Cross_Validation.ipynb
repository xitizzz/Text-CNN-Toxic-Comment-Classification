{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv1D, GlobalMaxPool1D, Dense, Dropout, Activation, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparam = {'sequence_len': 100,\n",
    "              'embedding_dim': 300, \n",
    "              'filters': 200, \n",
    "              'kernel_size': 3,\n",
    "              'dropout' : 0.8,\n",
    "              'batch_size': 512,\n",
    "              'epochs': 3,\n",
    "              'steps_per_epochs': None,\n",
    "              'early_stopping': False,\n",
    "              'vocab_size': None,\n",
    "              'learning_rate' : 0.0005,\n",
    "              'gradient_clip_value' : None,\n",
    "              'gradient_clip_norm' : None,\n",
    "              'validation_split': 0.1,\n",
    "              'missing_word_vectors': 'normal',\n",
    "              'conv_activation': 'relu', \n",
    "              'dense_activation':'relu',\n",
    "              'n_class': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if hyperparam['early_stopping']:\n",
    "    hyperparam['validation_split'] = max(0.1, hyperparam['validation_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = '_'.join(['CNN_Baseline', \n",
    "                 str(hyperparam['sequence_len']), \n",
    "                 str(hyperparam['filters']), \n",
    "                 str(hyperparam['kernel_size']), \n",
    "                 str(int(hyperparam['dropout']*100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_predictions = False\n",
    "save_model = False\n",
    "use_best_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    word_vec\n",
    "except NameError:\n",
    "    if os.path.exists('./data/GoogleNews-vectors-negative300.bin'):\n",
    "        word_vec = KeyedVectors.load_word2vec_format(fname='./data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    elif os.path.exists('./data/GoogleNews-vectors-negative300.bin.gz'):\n",
    "        google_w2v = gzip.open('./data/GoogleNews-vectors-negative300.bin.gz', 'rb')\n",
    "        word_vec = KeyedVectors.load_word2vec_format(fname=google_w2v, binary=True)\n",
    "        del google_w2v\n",
    "    else:\n",
    "        print('Embedings not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=hyperparam['vocab_size'], filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train['comment_text'].astype('str').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_text = test['comment_text'].astype('str').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train.loc[train['toxic']==0, train.columns[2:]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_seq = tokenizer.texts_to_sequences(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 193264\n"
     ]
    }
   ],
   "source": [
    "if not hyperparam['vocab_size']:\n",
    "    hyperparam['vocab_size'] = len(tokenizer.word_index)\n",
    "print('Vocab Size:', hyperparam['vocab_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if hyperparam['missing_word_vectors']=='normal':\n",
    "    embed_list = []\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index >= hyperparam['vocab_size']: \n",
    "            continue\n",
    "        try:\n",
    "            embed_list.append(word_vec.wv[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    a = np.array(embed_list)\n",
    "    embedding_matrix = np.array(np.random.normal(a.mean(), a.std(), (hyperparam['vocab_size'], hyperparam['embedding_dim'])), dtype=np.float32)\n",
    "    del embed_list\n",
    "    del a\n",
    "else:\n",
    "    embedding_matrix = np.zeros((hyperparam['vocab_size'], hyperparam['embedding_dim']), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unknown_count = 0\n",
    "unknown_freq = {}\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index >= hyperparam['vocab_size']: \n",
    "            continue\n",
    "    try:\n",
    "        embedding_matrix[index, :] = word_vec.wv[word]\n",
    "    except KeyError:\n",
    "        unknown_freq[word] = tokenizer.word_counts[word]\n",
    "        unknown_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown words 127113\n"
     ]
    }
   ],
   "source": [
    "print('Unknown words', unknown_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Freq 1450599\n"
     ]
    }
   ],
   "source": [
    "print('Unknown Freq', sum(unknown_freq.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(train_seq, maxlen=hyperparam['sequence_len'], truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mini_batch_generator(X_train, y_train):\n",
    "#     global X_train, y_train\n",
    "    while True:\n",
    "        yield (X_train[:hyperparam['batch_size'], :], y_train[:hyperparam['batch_size'], :])\n",
    "        X_train = np.roll(X_train, axis=0, shift=-hyperparam['batch_size'])\n",
    "        y_train = np.roll(y_train, axis=0, shift=-hyperparam['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computation_graph():\n",
    "    model  = Sequential()\n",
    "    model.add(Embedding(hyperparam['vocab_size'], hyperparam['embedding_dim'], weights=[embedding_matrix], name='Embedding_Layer'))\n",
    "    model.add(Conv1D(filters=hyperparam['filters'], \n",
    "                     kernel_size=hyperparam['kernel_size'],\n",
    "                     activation = hyperparam['conv_activation'],\n",
    "                     name= '_'.join(['Convolution_1D', str(hyperparam['filters']), str(hyperparam['kernel_size']), str(hyperparam['conv_activation'])])\n",
    "                    ))\n",
    "    model.add(GlobalMaxPool1D(name='Global_Max_Pooling'))\n",
    "    model.add(Dense(units=hyperparam['filters'], name='Dense_'+str(hyperparam['filters'])))\n",
    "    model.add(Dropout(rate=hyperparam['dropout'], name = 'Dropout_' + str(hyperparam['dropout'])))\n",
    "    model.add(Activation(hyperparam['dense_activation'], name='Activation_'+str(hyperparam['dense_activation'])))\n",
    "    model.add(Dense(units=hyperparam['n_class'], activation='sigmoid', name='Dense_'+str(hyperparam['n_class'])+'_Sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_fold(X_train, y_train, X_val, y_val):\n",
    "    model = None\n",
    "    model = computation_graph()\n",
    "    validation_data = (X_val, y_val)\n",
    "    if hyperparam['early_stopping']:\n",
    "        validation_data = (X_val, y_val)\n",
    "        callback = [EarlyStopping(verbose=1)]\n",
    "        if hyperparam['steps_per_epochs']:\n",
    "            callback = [EarlyStopping(verbose=1, patience=5)]\n",
    "    else:\n",
    "        callback = None   \n",
    "        validation_data = None\n",
    "    \n",
    "    if hyperparam['gradient_clip_norm'] is None and hyperparam['gradient_clip_value'] is None:\n",
    "        model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(hyperparam['learning_rate']),\n",
    "                  metrics=['accuracy'])\n",
    "    elif hyperparam['gradient_clip_norm'] is None:\n",
    "        model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(hyperparam['learning_rate'], \n",
    "                  clipvalue=hyperparam['gradient_clip_value']),\n",
    "                  metrics=['accuracy'])\n",
    "    elif hyperparam['gradient_clip_value'] is None:\n",
    "        model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(hyperparam['learning_rate'], \n",
    "                  clipnorm = hyperparam['gradient_clip_norm']),\n",
    "                  metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(hyperparam['learning_rate'], \n",
    "                  clipvalue=hyperparam['gradient_clip_value'],\n",
    "                  clipnorm = hyperparam['gradient_clip_norm']),\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    if hyperparam['steps_per_epochs']:\n",
    "        model = computation_graph()\n",
    "        history = model.fit_generator(generator=mini_batch_generator(X_train, y_train),\n",
    "                              epochs=hyperparam['epochs'], \n",
    "                              callbacks=callback,\n",
    "                              validation_data = validation_data, \n",
    "                              steps_per_epoch=hyperparam['steps_per_epochs'])\n",
    "    else:\n",
    "        history = model.fit(x=X_train, y=y_train,\n",
    "                          validation_data = validation_data,\n",
    "                          epochs=hyperparam['epochs'],\n",
    "                          batch_size=hyperparam['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          callbacks=callback)\n",
    "    sc = model.evaluate(x=X_val, y=y_val, batch_size = hyperparam['batch_size'])\n",
    "    y_score = model.predict(X_val)\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    return sc, history, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = computation_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Embedding_Layer (Embedding)  (None, None, 300)         57979200  \n",
      "_________________________________________________________________\n",
      "Convolution_1D_200_3_relu (C (None, None, 200)         180200    \n",
      "_________________________________________________________________\n",
      "Global_Max_Pooling (GlobalMa (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_200 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "Dropout_0.8 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Activation_relu (Activation) (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_6_Sigmoid (Dense)      (None, 6)                 1206      \n",
      "=================================================================\n",
      "Total params: 58,200,806\n",
      "Trainable params: 58,200,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 24s 169us/step - loss: 0.1292 - acc: 0.9598\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 22s 151us/step - loss: 0.0567 - acc: 0.9802\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 21s 149us/step - loss: 0.0485 - acc: 0.9822\n",
      "15958/15958 [==============================] - 0s 20us/step\n",
      "\n",
      "Loss: 0.0478\t Accuracy: 0.9818\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 23s 158us/step - loss: 0.1286 - acc: 0.9603\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 22s 150us/step - loss: 0.0567 - acc: 0.9802\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 22s 152us/step - loss: 0.0487 - acc: 0.9823\n",
      "15957/15957 [==============================] - 0s 20us/step\n",
      "\n",
      "Loss: 0.0489\t Accuracy: 0.9820\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 23s 160us/step - loss: 0.1200 - acc: 0.9647\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 22s 152us/step - loss: 0.0562 - acc: 0.9804\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 22s 152us/step - loss: 0.0489 - acc: 0.9821\n",
      "15957/15957 [==============================] - 0s 20us/step\n",
      "\n",
      "Loss: 0.0464\t Accuracy: 0.9823\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 23s 160us/step - loss: 0.1341 - acc: 0.9582\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 22s 152us/step - loss: 0.0579 - acc: 0.9800\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 22s 152us/step - loss: 0.0499 - acc: 0.9818\n",
      "15957/15957 [==============================] - 0s 21us/step\n",
      "\n",
      "Loss: 0.0478\t Accuracy: 0.9820\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 23s 162us/step - loss: 0.1352 - acc: 0.9590\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 22s 155us/step - loss: 0.0577 - acc: 0.9802\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 22s 156us/step - loss: 0.0491 - acc: 0.9822\n",
      "15957/15957 [==============================] - 0s 21us/step\n",
      "\n",
      "Loss: 0.0490\t Accuracy: 0.9819\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 23s 162us/step - loss: 0.1182 - acc: 0.9634\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 22s 155us/step - loss: 0.0562 - acc: 0.9804\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 22s 156us/step - loss: 0.0485 - acc: 0.9822\n",
      "15957/15957 [==============================] - 0s 21us/step\n",
      "\n",
      "Loss: 0.0485\t Accuracy: 0.9822\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 23s 163us/step - loss: 0.1360 - acc: 0.9567\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 22s 156us/step - loss: 0.0571 - acc: 0.9805\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 23s 157us/step - loss: 0.0494 - acc: 0.9822\n",
      "15957/15957 [==============================] - 0s 22us/step\n",
      "\n",
      "Loss: 0.0496\t Accuracy: 0.9815\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 24s 166us/step - loss: 0.1392 - acc: 0.9547\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 22s 152us/step - loss: 0.0591 - acc: 0.9796\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 23s 158us/step - loss: 0.0506 - acc: 0.9817\n",
      "15957/15957 [==============================] - 0s 21us/step\n",
      "\n",
      "Loss: 0.0477\t Accuracy: 0.9820\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 24s 165us/step - loss: 0.1419 - acc: 0.9543\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 23s 157us/step - loss: 0.0573 - acc: 0.9801\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 23s 157us/step - loss: 0.0487 - acc: 0.9821\n",
      "15957/15957 [==============================] - 0s 21us/step\n",
      "\n",
      "Loss: 0.0474\t Accuracy: 0.9822\n",
      "--------------------\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/3\n",
      "143614/143614 [==============================] - 24s 166us/step - loss: 0.1219 - acc: 0.9618\n",
      "Epoch 2/3\n",
      "143614/143614 [==============================] - 23s 159us/step - loss: 0.0562 - acc: 0.9803\n",
      "Epoch 3/3\n",
      "143614/143614 [==============================] - 23s 159us/step - loss: 0.0481 - acc: 0.9821\n",
      "15957/15957 [==============================] - 0s 21us/step\n",
      "\n",
      "Loss: 0.0450\t Accuracy: 0.9830\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=22, shuffle=True)\n",
    "history = []\n",
    "score = []\n",
    "y_actual = []\n",
    "y_predicted = []\n",
    "k = 1\n",
    "for train_id, validation_id in kfold.split(X):\n",
    "    print('-'*20)\n",
    "    print('\\nFold ', k)\n",
    "    X_train, X_val, y_train, y_val = X[train_id, :], X[validation_id, :], y[train_id, :], y[validation_id, :]\n",
    "    sc, his, y_score = cross_validation_fold(X_train, y_train,  X_val, y_val)\n",
    "    print('\\nLoss: {:.4f}\\t Accuracy: {:.4f}'.format(sc[0], sc[1]))\n",
    "    score.append(sc)\n",
    "    history.append(his)\n",
    "    y_actual.append(y_val)\n",
    "    y_predicted.append(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_actual_np = np.vstack(y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_np = np.vstack(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_bin = np.array(y_predicted_np > 0.5, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_bin = y_bin - 5**-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin = np.abs(y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "       ...,\n",
       "       [0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "       [0.8, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2, 0.2, 0.2, 0.2]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.hstack((y_actual_np, y_predicted_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5250115394592285"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(rd[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>157976.000000</td>\n",
       "      <td>157976.0</td>\n",
       "      <td>1.579760e+05</td>\n",
       "      <td>1.579760e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.086716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.992415e-02</td>\n",
       "      <td>7.216651e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.281419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.231959e-01</td>\n",
       "      <td>4.010646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.239653e-07</td>\n",
       "      <td>7.650033e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.100408e-04</td>\n",
       "      <td>1.932321e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.279467e-03</td>\n",
       "      <td>1.208696e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.985795e-03</td>\n",
       "      <td>1.525840e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.998904e-01</td>\n",
       "      <td>5.453960e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1             6             7\n",
       "count  157976.000000  157976.0  1.579760e+05  1.579760e+05\n",
       "mean        0.086716       0.0  7.992415e-02  7.216651e-03\n",
       "std         0.281419       0.0  2.231959e-01  4.010646e-02\n",
       "min         0.000000       0.0  9.239653e-07  7.650033e-11\n",
       "25%         0.000000       0.0  3.100408e-04  1.932321e-07\n",
       "50%         0.000000       0.0  1.279467e-03  1.208696e-06\n",
       "75%         0.000000       0.0  9.985795e-03  1.525840e-05\n",
       "max         1.000000       0.0  9.998904e-01  5.453960e-01"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.loc[rd[1]==0, [0, 1, 6, 7]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05643638829732237"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_true=y_actual_np[:], y_pred=y_bin[:])/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09940792493605383\n",
      "0.023097560937440975\n",
      "0.05464086626479782\n",
      "0.01393140877197082\n",
      "0.06726162203861821\n",
      "0.028514292935166604\n"
     ]
    }
   ],
   "source": [
    "a  = 0 \n",
    "for i in range(0, 6):\n",
    "    print(log_loss(y_true=y_actual_np[:, i], y_pred=y_predicted_np[:, i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
